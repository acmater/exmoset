{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lined-tractor",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa162899014a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_values_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chemprop/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chemprop/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chemprop/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    437\u001b[0m                                  \"if n_samples >= n_features\")\n\u001b[1;32m    438\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0m\u001b[1;32m    440\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6776179 0.3223821 0.       ]\n",
      "[0.50939423 0.35135573 0.        ]\n"
     ]
    }
   ],
   "source": [
    "mol1 = np.array([1,0.26,0.39])\n",
    "mol2 = np.array([1,0.94,0.61])\n",
    "mol3 = np.array([1,0.52,0.93])\n",
    "\n",
    "mols = np.array([mol1,mol2,mol3])\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(mols)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romantic-agenda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.07848889, 0.04915556])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(mols,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "material-anniversary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "a = \"C#COC\"\n",
    "mol = Chem.MolFromSmiles(a)\n",
    "\n",
    "len(mol.GetAtoms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "unsigned-monthly",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'entropy_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-127f34ed881d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"molsim/data/QM9_Data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SMILES\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD/molsim/molsim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolecule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PhD/molsim/molsim/atom/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontainsatom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PhD/molsim/molsim/atom/containsatom.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmolsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperty\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mContainsAtom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProperty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/PhD/molsim/molsim/property/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproperty\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PhD/molsim/molsim/property/property.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mentropy_estimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mABC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'entropy_estimators'"
     ]
    }
   ],
   "source": [
    "from molsim.data import * \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"molsim/data/QM9_Data.csv\",index_col=\"SMILES\")\n",
    "#df[\"index\"] = np.arange(len(df))\n",
    "#df[np.logical_and((df[\"Isotropic Polarizability\"] > 30).to_numpy(), (df[\"Isotropic Polarizability\"] < 35).to_numpy())][\"SMILES\"].to_numpy()\n",
    "df.loc[mols3]#.to_csv(\"Mini_DF.csv\",index_label='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "comic-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.generic:\n",
      "\n",
      "to_csv(path_or_buf: 'Optional[FilePathOrBuffer]' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'Optional[str]' = None, columns: 'Optional[Sequence[Label]]' = None, header: 'Union[bool_t, List[str]]' = True, index: 'bool_t' = True, index_label: 'Optional[IndexLabel]' = None, mode: 'str' = 'w', encoding: 'Optional[str]' = None, compression: 'CompressionOptions' = 'infer', quoting: 'Optional[int]' = None, quotechar: 'str' = '\"', line_terminator: 'Optional[str]' = None, chunksize: 'Optional[int]' = None, date_format: 'Optional[str]' = None, doublequote: 'bool_t' = True, escapechar: 'Optional[str]' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'Optional[str]' method of pandas.core.frame.DataFrame instance\n",
      "    Write object to a comma-separated values (csv) file.\n",
      "    \n",
      "    .. versionchanged:: 0.24.0\n",
      "        The order of arguments for Series was changed.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str or file handle, default None\n",
      "        File path or object, if None is provided the result is returned as\n",
      "        a string.  If a non-binary file object is passed, it should be opened\n",
      "        with `newline=''`, disabling universal newlines. If a binary\n",
      "        file object is passed, `mode` might need to contain a `'b'`.\n",
      "    \n",
      "        .. versionchanged:: 0.24.0\n",
      "    \n",
      "           Was previously named \"path\" for Series.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "           Support for binary file objects was introduced.\n",
      "    \n",
      "    sep : str, default ','\n",
      "        String of length 1. Field delimiter for the output file.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, default None\n",
      "        Format string for floating point numbers.\n",
      "    columns : sequence, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of strings is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    \n",
      "        .. versionchanged:: 0.24.0\n",
      "    \n",
      "           Previously defaulted to False for Series.\n",
      "    \n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the object uses MultiIndex. If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R.\n",
      "    mode : str\n",
      "        Python write mode, default 'w'.\n",
      "    encoding : str, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      "        is a non-binary file object.\n",
      "    compression : str or dict, default 'infer'\n",
      "        If str, represents compression mode. If dict, value at 'method' is\n",
      "        the compression mode. Compression mode may be any of the following\n",
      "        possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
      "        compression mode is 'infer' and `path_or_buf` is path-like, then\n",
      "        detect compression mode from the following extensions: '.gz',\n",
      "        '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
      "        and mode is one of {'zip', 'gzip', 'bz2'}, or inferred as\n",
      "        one of the above, other entries passed as\n",
      "        additional compression options.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           May now be a dict with key 'method' as compression mode\n",
      "           and other entries as additional compression options if\n",
      "           compression mode is 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "           Passing compression options as keys in dict is\n",
      "           supported for compression modes 'gzip' and 'bz2'\n",
      "           as well as 'zip'.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Compression is supported for binary file objects.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "            Previous versions forwarded dict entries for 'gzip' to\n",
      "            `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      "            setting `mtime`.\n",
      "    \n",
      "    quoting : optional constant from csv module\n",
      "        Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric.\n",
      "    quotechar : str, default '\\\"'\n",
      "        String of length 1. Character used to quote fields.\n",
      "    line_terminator : str, optional\n",
      "        The newline character or character sequence to use in the output\n",
      "        file. Defaults to `os.linesep`, which depends on the OS in which\n",
      "        this method is called ('\\n' for linux, '\\r\\n' for Windows, i.e.).\n",
      "    \n",
      "        .. versionchanged:: 0.24.0\n",
      "    chunksize : int or None\n",
      "        Rows to write at a time.\n",
      "    date_format : str, default None\n",
      "        Format string for datetime objects.\n",
      "    doublequote : bool, default True\n",
      "        Control quoting of `quotechar` inside a field.\n",
      "    escapechar : str, default None\n",
      "        String of length 1. Character used to escape `sep` and `quotechar`\n",
      "        when appropriate.\n",
      "    decimal : str, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data.\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc., if using a URL that will\n",
      "        be parsed by ``fsspec``, e.g., starting \"s3://\", \"gcs://\". An error\n",
      "        will be raised if providing this argument with a non-fsspec URL.\n",
      "        See the fsspec and backend storage implementation docs for the set of\n",
      "        allowed keys and values.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting csv format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_csv : Load a CSV file into a DataFrame.\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      "    ...                    'mask': ['red', 'purple'],\n",
      "    ...                    'weapon': ['sai', 'bo staff']})\n",
      "    >>> df.to_csv(index=False)\n",
      "    'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      "    \n",
      "    Create 'out.zip' containing 'out.csv'\n",
      "    \n",
      "    >>> compression_opts = dict(method='zip',\n",
      "    ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      "    >>> df.to_csv('out.zip', index=False,\n",
      "    ...           compression=compression_opts)  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "isolated-request",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6402312320438752"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import log, e\n",
    "\n",
    "\n",
    "def entropy(labels, base=None):\n",
    "    \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    value,counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / n_labels\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    ent = 0.\n",
    "\n",
    "    # Compute entropy\n",
    "    base = e if base is None else base\n",
    "    for i in probs:\n",
    "        ent -= i * log(i, base)\n",
    "\n",
    "    return ent\n",
    "\n",
    "entropy(np.array([7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]),base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "imported-quantum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12565805017256743"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "chemical-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-arthritis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "chemprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
